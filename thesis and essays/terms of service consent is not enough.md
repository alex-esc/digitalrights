# Consent

In the face of the tech-lash we find ourselves pivoting from old design philosophies. No more infinitely scrolling feeds or forever buzzing notifications, don't compete for human attention, use data transparently, and other noble causes under the banner of *humane technology*. But one thing we can't ignore, get rid of, overcompensate for, or maneuver around is that computer software is guided by consent, in a different kind of manner. Decisions are made by software all the time; first the programmer must make the conscious decision to design flowcharts in a particular way to solve a problem or to achieve a goal, then the flowchart bare-bones program must be converted into machine readable code, the lines of code are interpreted by the computer as steps to follow, now the crucial moment occurs, a program runs and then it will inevitably hit a fork on the road, we find ourselves in a rhombus on the flowchart, a decision must be made either by the user or by external factors (often made out of abstractions of inputs of users of foreign systems or by sensors tuned to enforce a human bias), meaning that all computer programs are at some point binded by human consent.

At the beginning software was consciously designed, when the software runs it needs conscious input to continue to the next instruction, and at the end user level whoever is using the software inevitably gets interrupted to then make the a decision about the program, this end user decision can be what the program needs to continue running or an abstract decision brought by the sum total of the program: *Facebook sends you a notification, you stop for a moment in your head, get your phone out and ponder if you ought to open the notification, if you do open it it creates more possibilities, and at all point decisions are required*. Software is created by consent, it requires consent to function, and it creates more decisions for humans to ponder. With the importance of consent in software it then becomes ridiculous what the humane technology and it's followers desire for new generation apps to behave like.

The humane tech moment is routinely critical of the status quo of digital platforms, and then imagines a wold without the perceived flaws. One of this flaws is the lack of consent, they see evil software as a conscious trickster, a maliciously designed app works in such a way that once you press *I have read and accept the terms and conditions* you are screwed. Now this charlatan app can do what it pleases with your data, surveil you by digital means, compromise your identity, manipulate you with selective content or advertisement material, et cetera. The tech humanists claim that the problem lies predominately in people signing a contract with the devil, and that an alternative must arise, an alternative graphical interface that makes it obvious to the end user what are they getting into. Imagine an appstore that after taping the download button it will prompt you a message saying that Facebook is filed with propaganda, its manipulative, breaks up families and friends, and exploits its workers; all with nice animations and a friendly mascot turning his head and saying *don't do it!* But this fantasy GUI would not stop people from signing their humanity, data and dignity away. We already have similar pop-up alert messages on android saying *hey, this app can use your camera and read your contacts whenever it wants, do you agree?* And we do agree! We have no choice but to submit!

We can only give our consent in this type of situations, but not because consent in software only applies when accepting the terms of service, but because choice and consent are built into the most basic fundamental framework of software. Designing a program is an exercise of choice, feeding a program is an exercise of choice, and using a program is an exercise of choice too. Its not that we need more explicit choices or more transparent consent, we need more than consent. This situation echoes a topic that some technologists fail to understand: *Women*. The feminist movement has been pushing for a more fair world for women, to wash away the violence and oppression built up throughout generations. But the systemic oppression of women seems like the next boogie-man for the people performing the oppression, usually male. They look at acts of rape and sexual violence like consensual acts, since in a perverted way the victims did not reject or attempted to violently end the sexual act, because deep inside *they wanted it*. This horrible line of argument fails in many levels, but the most relevant to the software conversation is that most women do not simply "desire" sex with whomever is "strong enough" to take her, no, in most cases women are manipulated against their will to do said acts: Social pressure to give in, women are though from birth never to respond with aggression and always conform and repress, because women are so desired by desperate "alpha" men than they usually resort to drugs and or alcohol to numb their senses, and so on. No, women did not consent to this, they don't secretly want this, they were manipulated into this mess; even if they do say yes, even if they do consent it's simply not enough, because consent as the end-all-be-all of justice ignores the manipulation and oppressive gymnastics required to get some women to say yes, or at least to keep their no to themselves. Consent is not enough because there is an underlying dynamic, system, or unwritten rule to overwrite consent at all cost.

In software, the type of consent we experience is similarly rendered useless. Software users are not drugged into downloading the cash app, but our senses are numbed in different ways, one of them is the constant decisions needed to use technology: We are thought to click on "next" wile installing new programs, and we are prompted with micro decisions by our phones. We can't go to work, function inside a modern high school or university, socialize online without clicking on *I accept the terms and conditions*. Our digital environment has been set up to render our consent meaningless. To battle this phenomenon with more explicit consent, more transparent menus and clear explanations of what happens with our data, is a lost game. To make consent meaningful we don't need more of it, zero multiplied times a hundred is still zero, we need to undermine the social structure below technology. If our environment invites us to make actual choices we would like in a different digital frontier, but today the choices presented on the menu are limited and manipulative, not by themselves, the issue is not the button menu design, or the specific program, but the entire operating system.